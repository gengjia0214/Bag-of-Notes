{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Learning Note - Table Joins\n",
    "\n",
    "Jia Geng | gjia0214@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_252\"\r\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~19.10-b09)\r\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\r\n"
     ]
    }
   ],
   "source": [
    "# check java version \n",
    "# use sudo update-alternatives --config java to switch java version if needed.\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://unknown40A5EF2BBD8A:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TableJoinExamples</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f90542c7d50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('TableJoinExamples').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Operations\n",
    "\n",
    "Join operation: `left.xJoin(right)` is to bring left and right tables together by one or more keys. Common join types include:\n",
    "- **inner joins**: keep rows with from both tables keys exist in both left&right table\n",
    "- **outer joins**: keep rows from both tables with keys exist in either left or right table\n",
    "- **left outer joins**: keep rows from both tables with keys exist in left table\n",
    "- **right outer joins**: keep rows from both tables  with keys exist in the right table\n",
    "- **left semi joins**: keep rows from only left tables with keys exist in the left&right table. Result only contain columns from left table.\n",
    "- **left anti joins**: keep rows from only left tables with keys NOT exist in the right table,  Result only contain columns from left table.\n",
    "- **natural joins**: join by matching the columns between two datasets with the same names\n",
    "    - be careful when using this as column name could be the same but indicating different things!!\n",
    "- **cross joins**: match every row in the left table with every row in the right table\n",
    "\n",
    "In spark:\n",
    "```\n",
    "df_left.join(df_left, on=, how=)\n",
    "```\n",
    "\n",
    "When working with array column, there are many array based operations under `pyspark.sql.functions` that can be used for join expression.\n",
    "\n",
    "To deal with duplicate col name between two DF.\n",
    "- use col name as the expression input instead of boolean\n",
    "    - use this when the two columns from left and right tables are referring the same \n",
    "- drop a column after the join\n",
    "- rename a column before the join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----------------+---------------+\n",
      "| id|name|graduate_program|  person_status|\n",
      "+---+----+----------------+---------------+\n",
      "|  0|Bill|               0|          [100]|\n",
      "|  1|Matt|               1|[500, 250, 100]|\n",
      "|  2|Zack|               1|     [250, 100]|\n",
      "+---+----+----------------+---------------+\n",
      "\n",
      "+---+------+----------+------+\n",
      "| id|degree|department|school|\n",
      "+---+------+----------+------+\n",
      "|  0|    MS|       ACE|    UC|\n",
      "|  2|    MS|      ECCS|    UC|\n",
      "|  1|   PhD|      ECCS|    UC|\n",
      "+---+------+----------+------+\n",
      "\n",
      "+---+-----------+\n",
      "| id|     status|\n",
      "+---+-----------+\n",
      "|500|         VP|\n",
      "|250| PMC Member|\n",
      "|100|Contributor|\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set up the example\n",
    "person_data = [(0, 'Bill', 0, [100]), (1, 'Matt', 1, [500, 250, 100]), (2, 'Zack', 1, [250, 100])]  \n",
    "person_coln = ['id', 'name', 'graduate_program', 'person_status']\n",
    "person = spark.createDataFrame(person_data, person_coln)\n",
    "\n",
    "program_data = [(0, 'MS', 'ACE', 'UC'), (2, 'MS', 'ECCS', 'UC'), (1, 'PhD', 'ECCS', 'UC')]\n",
    "program_coln = ['id', 'degree', 'department', 'school']\n",
    "program = spark.createDataFrame(program_data, program_coln)\n",
    "\n",
    "status_data = [(500, 'VP'), (250, 'PMC Member'), (100, 'Contributor')]\n",
    "status_coln = ['id', 'status']\n",
    "statusDF = spark.createDataFrame(status_data, status_coln)\n",
    "\n",
    "person.show()\n",
    "program.show()\n",
    "statusDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----------------+---------------+---+------+----------+------+\n",
      "| id|name|graduate_program|  person_status| id|degree|department|school|\n",
      "+---+----+----------------+---------------+---+------+----------+------+\n",
      "|  0|Bill|               0|          [100]|  0|    MS|       ACE|    UC|\n",
      "|  1|Matt|               1|[500, 250, 100]|  1|   PhD|      ECCS|    UC|\n",
      "|  2|Zack|               1|     [250, 100]|  1|   PhD|      ECCS|    UC|\n",
      "+---+----+----------------+---------------+---+------+----------+------+\n",
      "\n",
      "+---+----+----------------+---------------+---+------+----------+------+\n",
      "| id|name|graduate_program|  person_status| id|degree|department|school|\n",
      "+---+----+----------------+---------------+---+------+----------+------+\n",
      "|  0|Bill|               0|          [100]|  2|    MS|      ECCS|    UC|\n",
      "|  0|Bill|               0|          [100]|  1|   PhD|      ECCS|    UC|\n",
      "|  1|Matt|               1|[500, 250, 100]|  0|    MS|       ACE|    UC|\n",
      "|  1|Matt|               1|[500, 250, 100]|  2|    MS|      ECCS|    UC|\n",
      "|  2|Zack|               1|     [250, 100]|  0|    MS|       ACE|    UC|\n",
      "|  2|Zack|               1|     [250, 100]|  2|    MS|      ECCS|    UC|\n",
      "+---+----+----------------+---------------+---+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inner join person and program on program id\n",
    "# it kept the id column from both table\n",
    "# id from person is the person id\n",
    "# id from program is the program id\n",
    "# they are different!\n",
    "person.join(program, person['graduate_program'] == program['id'], 'inner').show()\n",
    "person.join(program, person['graduate_program'] != program['id'], 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------------+---------------+---+------+----------+------+\n",
      "|  id|name|graduate_program|  person_status| id|degree|department|school|\n",
      "+----+----+----------------+---------------+---+------+----------+------+\n",
      "|   0|Bill|               0|          [100]|  0|    MS|       ACE|    UC|\n",
      "|   1|Matt|               1|[500, 250, 100]|  1|   PhD|      ECCS|    UC|\n",
      "|   2|Zack|               1|     [250, 100]|  1|   PhD|      ECCS|    UC|\n",
      "|null|null|            null|           null|  2|    MS|      ECCS|    UC|\n",
      "+----+----+----------------+---------------+---+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# outer join person and program on program id\n",
    "# if id can not be matched, missing side will be null\n",
    "person.join(program, person['graduate_program'] == program['id'], 'outer').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----------------+---------------+---+------+----------+------+\n",
      "| id|name|graduate_program|  person_status| id|degree|department|school|\n",
      "+---+----+----------------+---------------+---+------+----------+------+\n",
      "|  0|Bill|               0|          [100]|  0|    MS|       ACE|    UC|\n",
      "|  1|Matt|               1|[500, 250, 100]|  1|   PhD|      ECCS|    UC|\n",
      "|  2|Zack|               1|     [250, 100]|  1|   PhD|      ECCS|    UC|\n",
      "+---+----+----------------+---------------+---+------+----------+------+\n",
      "\n",
      "+----+----+----------------+---------------+---+------+----------+------+\n",
      "|  id|name|graduate_program|  person_status| id|degree|department|school|\n",
      "+----+----+----------------+---------------+---+------+----------+------+\n",
      "|   0|Bill|               0|          [100]|  0|    MS|       ACE|    UC|\n",
      "|   1|Matt|               1|[500, 250, 100]|  1|   PhD|      ECCS|    UC|\n",
      "|   2|Zack|               1|     [250, 100]|  1|   PhD|      ECCS|    UC|\n",
      "|null|null|            null|           null|  2|    MS|      ECCS|    UC|\n",
      "+----+----+----------------+---------------+---+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# left/right outer join person and program on program id\n",
    "# only keep the rows from the left/right table\n",
    "person.join(program, person['graduate_program'] == program['id'], 'left_outer').show()\n",
    "person.join(program, person['graduate_program'] == program['id'], 'right_outer').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+------+\n",
      "| id|degree|department|school|\n",
      "+---+------+----------+------+\n",
      "|  0|    MS|       ACE|    UC|\n",
      "|  1|   PhD|      ECCS|    UC|\n",
      "+---+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# left semi joins - only include shared key rows\n",
    "# DOES NOT include anything from right table\n",
    "# right table only provide the keys for 'filtering' the rows\n",
    "program.join(person, person['graduate_program'] == program['id'], 'left_semi').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+------+\n",
      "| id|degree|department|school|\n",
      "+---+------+----------+------+\n",
      "|  2|    MS|      ECCS|    UC|\n",
      "+---+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# left anti joins - exlcude shared key rows\n",
    "# DOES NOT include anything from right table\n",
    "# right table only provide the keys for 'filtering' the rows\n",
    "program.join(person, person['graduate_program'] == program['id'], 'left_anti').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------------+---------------+---+-----------+\n",
      "|personID|name|graduate_program|  person_status| id|     status|\n",
      "+--------+----+----------------+---------------+---+-----------+\n",
      "|       0|Bill|               0|          [100]|100|Contributor|\n",
      "|       1|Matt|               1|[500, 250, 100]|500|         VP|\n",
      "|       1|Matt|               1|[500, 250, 100]|250| PMC Member|\n",
      "|       1|Matt|               1|[500, 250, 100]|100|Contributor|\n",
      "|       2|Zack|               1|     [250, 100]|250| PMC Member|\n",
      "|       2|Zack|               1|     [250, 100]|100|Contributor|\n",
      "+--------+----+----------------+---------------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains, expr\n",
    "\n",
    "# some more complex example that including the array operatoins\n",
    "# here, must use expr(), if use arrary_contains(),  it does not work\n",
    "# because array_contain() takes a column and a value\n",
    "# here use expr(), we are telling to program to\n",
    "# find the person_status col from the two tables\n",
    "# find the id col from the two tables\n",
    "# ambiguoty is not allowed!\n",
    "expression = expr('array_contains(person_status, id)') \n",
    "\n",
    "# must rename the person id to avoid ambiguoty\n",
    "person.withColumnRenamed('id', 'personID').join(statusDF, expression).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

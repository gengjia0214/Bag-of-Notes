{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Learning Note - Recommendation\n",
    "Jia Geng | gjia0214@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='directory'></a>\n",
    "\n",
    "## Directory\n",
    "\n",
    "- [Data Source](https://github.com/databricks/Spark-The-Definitive-Guide/tree/master/data/)\n",
    "- [1. Alternative Least Square and Collaborate Filtering](#sec1)\n",
    "- [2. Model Params](#sec2)\n",
    "- [3. Evaluator and Metrics](#sec3)\n",
    "    - [3.1 Regression Metrics](#sec3-1)\n",
    "    - [3.2 Ranking Metrics](#sec3-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://unknown40A5EF2BBD8A:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MLexample</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0aa4bb0ed0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('MLexample').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|              value|\n",
      "+-------------------+\n",
      "|0::2::3::1424380312|\n",
      "+-------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+---------------------+\n",
      "|col                  |\n",
      "+---------------------+\n",
      "|[0, 2, 3, 1424380312]|\n",
      "+---------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+------+-------+------+----------+\n",
      "|userID|movieID|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     0|      2|   3.0|1424380312|\n",
      "+------+-------+------+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "1179 322\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/jgeng/Documents/Git/SparkLearning/book_data/sample_movielens_ratings.txt'\n",
    "data = spark.read.text(data_path)\n",
    "data.show(1)\n",
    "# how to convert strings into array of strings\n",
    "data = data.selectExpr(\"split(value, '::') as col\")\n",
    "data.show(1, False)\n",
    "\n",
    "# how to convert array of strings into columns\n",
    "data = data.selectExpr('cast(col[0] as int) as userID',\n",
    "                       'cast(col[1] as int) as movieID',\n",
    "                       'cast(col[2] as float) as rating',\n",
    "                       'cast(col[3] as long) as timestamp')\n",
    "data.show(1)\n",
    "train, test = data.randomSplit([0.8, 0.2])\n",
    "train.cache()\n",
    "test.cache()\n",
    "print(train.count(), test.count())\n",
    "print(train.where('rating is null').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Alternative Least Square and Collaborate Filtering <a id='sec1'></a>\n",
    "\n",
    "Spark have an implementatoin of Alternative Least Squares for Collaborative Filterinig. ALS finds a dimentional featue vector for each user an item such that the dot product of each user's feature vector with each item's feature vector approximates the user's rating for that item. The dataset should includes existing ratings between user-item pairs:\n",
    "- a user ID column (need to be int)\n",
    "- an item ID column (need to be int)\n",
    "- a rating column (need to be a float)\n",
    "    - the rating can be explicit: a numerical rating that the system should predict directly\n",
    "    - or implicit: rating represents the strength of interactions between a user and item (e.g. number of visits to a particular page)\n",
    "\n",
    "The goal for recommendation system is that: given an ipnut data frame, the model will produce feature vectors that can be used to predict user's rating for items they have not yet rated.\n",
    "\n",
    "Some potential problem of such system - **cold start problems**:\n",
    "- when introducing a new product that no user has expressed a preference for, the algorithm is not going to recommend it to many people.\n",
    "- if a new user are onboarding onto the platform, they might not have many ratings yet. Therefore the algorithm won't know what to recommend them.\n",
    "\n",
    "The MLlib can scale the algorithm to millions of users, millions of items and billions of ratings.\n",
    "\n",
    "[back to top](#directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Params <a id='sec2'></a>\n",
    "\n",
    "**Hyperparams**\n",
    "\n",
    "|Name|Input|Notes|\n",
    "|-|-|-|\n",
    "|rank|int|the dimension of the feature vectors learned for users and items. **Controls the bias and variance trade off.** Default is 10. \n",
    "|alpha|float|when traninig on implicit feedback, alpha sets a baseline confidence for preference. default is 1.0\n",
    "|regParam|float|default is 0.1\n",
    "|implicitPrefs|bool|whether training on implicit or explicit. default is explicity\n",
    "|nonnegative|bool|whether to place a non-negative (feature) constriants on the least square problem. default is False.\n",
    "\n",
    "**Training Params**\n",
    "\n",
    "|Name|Input|Notes|\n",
    "|-|-|-|\n",
    "|numUserBlocks|int|how many blocks to split the user into. default is 10|\n",
    "|numItemBlocks|int|how many blocks to split the items into. default is 10|\n",
    "|maxIter|int|total number of iterations over the data before stopping. default is 10\n",
    "|checkpointInterval|int|allow saving the checkpoints during training\n",
    "|seed|int|random seed for replicating results\n",
    "\n",
    "Rule of thumb to decide how much data to be put in each block:\n",
    "- one to five millions ratings per block\n",
    "- if data is less than that in each block, more blocks will not improve the algorithm performance.\n",
    "\n",
    "**Prediction Params**\n",
    "\n",
    "|Name|Input|Notes|\n",
    "|-|-|-|\n",
    "|coldStartStrategy|'nan', 'drop'| strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data.\n",
    "\n",
    "By default, Spark assign NaN prediction values when encountering a user that is not present in the actual model. However, if this happens during training, the NaN value will ruin the ability for the evaluator to properly measure the success of the model.\n",
    "\n",
    "Set to drop will drop any rows that contains NaN prediction so that the rest of the data will become valid for evaluation.\n",
    "\n",
    "[back to top](#directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: alpha for implicit preference (default: 1.0)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "coldStartStrategy: strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'. (default: nan)\n",
      "finalStorageLevel: StorageLevel for ALS model factors. (default: MEMORY_AND_DISK)\n",
      "implicitPrefs: whether to use implicit preference (default: False)\n",
      "intermediateStorageLevel: StorageLevel for intermediate datasets. Cannot be 'NONE'. (default: MEMORY_AND_DISK)\n",
      "itemCol: column name for item ids. Ids must be within the integer value range. (default: item)\n",
      "maxIter: max number of iterations (>= 0). (default: 10)\n",
      "nonnegative: whether to use nonnegative constraint for least squares (default: False)\n",
      "numItemBlocks: number of item blocks (default: 10)\n",
      "numUserBlocks: number of user blocks (default: 10)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "rank: rank of the factorization (default: 10)\n",
      "ratingCol: column name for ratings (default: rating)\n",
      "regParam: regularization parameter (>= 0). (default: 0.1)\n",
      "seed: random seed. (default: 3904191719059310447)\n",
      "userCol: column name for user ids. Ids must be within the integer value range. (default: user)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "print(ALS().explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userID: integer (nullable = true)\n",
      " |-- movieID: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS().setMaxIter(5)\\\n",
    "            .setRegParam(0.01)\\\n",
    "            .setUserCol('userID')\\\n",
    "            .setItemCol('movieID')\\\n",
    "            .setRatingCol('rating')\n",
    "alsclf = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+-----------+\n",
      "|userID|movieID|rating|timestamp |prediction |\n",
      "+------+-------+------+----------+-----------+\n",
      "|26    |31     |1.0   |1424380312|-1.9767356 |\n",
      "|27    |31     |1.0   |1424380312|-1.0848575 |\n",
      "|12    |31     |4.0   |1424380312|0.87788236 |\n",
      "|4     |31     |1.0   |1424380312|-0.2520102 |\n",
      "|8     |31     |3.0   |1424380312|2.2586     |\n",
      "|28    |85     |1.0   |1424380312|6.9975033  |\n",
      "|26    |85     |1.0   |1424380312|-0.6348226 |\n",
      "|23    |85     |1.0   |1424380312|-1.3387568 |\n",
      "|16    |65     |1.0   |1424380312|-0.518541  |\n",
      "|3     |65     |2.0   |1424380312|-0.20969684|\n",
      "|19    |65     |1.0   |1424380312|0.7038306  |\n",
      "|4     |65     |1.0   |1424380312|-0.31682414|\n",
      "|23    |65     |5.0   |1424380312|1.1317939  |\n",
      "|20    |53     |3.0   |1424380312|-1.670781  |\n",
      "|21    |53     |5.0   |1424380312|1.3977592  |\n",
      "|14    |53     |3.0   |1424380312|2.7680461  |\n",
      "|22    |78     |1.0   |1424380312|0.38458624 |\n",
      "|24    |78     |1.0   |1424380312|0.81120306 |\n",
      "|11    |78     |1.0   |1424380312|0.8233675  |\n",
      "|3     |34     |3.0   |1424380312|-0.8458854 |\n",
      "+------+-------+------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = alsclf.transform(test)\n",
    "predictions.show(20, False)\n",
    "predictions.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluator and Metrics <a id='sec3'></a>\n",
    "\n",
    "[back to top](#directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Regression Metrics <a id='sec3-1'></a>\n",
    "We can use a regression evaluator to measure the rmse of the prediction on the rating and the actual rating.\n",
    "\n",
    "[back to top](#directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2059] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "# get the rdd data\n",
    "input_data = predictions.select('rating', 'prediction').rdd.map(lambda x: (x[0], x[1]))\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.053136657182337"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the regression metrics\n",
    "metrics = RegressionMetrics(input_data)\n",
    "metrics.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ranking Metrics <a id='sec3-2'></a>\n",
    "There is another tool provided in Spark: `RankingMetrics` that provides more sophisticated way of measuring the performance of the recommendation system. Ranking metrics does not focus on the value of the rank. It focuses on whether the algorithm recommeds an already ranked item again to a user.\n",
    "\n",
    "For example, if there is a movie that a person gives a very high rate. Will the system recommend this movie to the person? \n",
    "\n",
    "From a high level point of view, wo can do:\n",
    "- predict the person's rating on every movie in the dataset\n",
    "- rank the movie by predicted ratings\n",
    "- check whether the high-rated movie is associate with a high rank\n",
    "\n",
    "In spark, we do:\n",
    "- train model and make predictions on the testing set\n",
    "- set up a ranking threshold to represent the 'high ranking'\n",
    "- filter the ground truth ==> aggregate on user to put the rated items into a list (DF A)\n",
    "- filter the predicted ranking ==> aggregate on user to put the rated items into a list (DF B)\n",
    "- join A and B on the users\n",
    "- call the ranking metrics on the joined DF's RDD data (Only take top k from the prediction columns as recommendations)\n",
    "\n",
    "[back to top](#directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|userID|             truths|\n",
      "+------+-------------------+\n",
      "|    28|[81, 19, 2, 62, 92]|\n",
      "|    26|       [88, 24, 94]|\n",
      "|    27|       [75, 55, 80]|\n",
      "+------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------+-------------------+\n",
      "|userID|        predictions|\n",
      "+------+-------------------+\n",
      "|    28|[85, 2, 58, 95, 92]|\n",
      "|    26|           [88, 44]|\n",
      "|    27|               [80]|\n",
      "+------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------+-------------------+-------------------+\n",
      "|userID|             truths|        predictions|\n",
      "+------+-------------------+-------------------+\n",
      "|    28|[81, 19, 2, 62, 92]|[85, 2, 58, 95, 92]|\n",
      "|    26|       [88, 24, 94]|           [88, 44]|\n",
      "|    27|       [75, 55, 80]|               [80]|\n",
      "+------+-------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# get the all movies with high actual rating (>2.5 for this case)\n",
    "filtered_truth = predictions.where('rating > 2.5')\n",
    "\n",
    "# use collect set to aggregate the high rating movies for each user\n",
    "agg_truth = filtered_truth.groupBy('userID').agg(expr('collect_set(movieID) as truths'))\n",
    "agg_truth.show(3)\n",
    "\n",
    "# get all movies with high predicted rating \n",
    "filtered_pred = predictions.where('prediction > 2.5')\n",
    "agg_pred = filtered_pred.groupBy('userID').agg(expr('collect_set(movieID) as predictions'))\n",
    "agg_pred.show(3)\n",
    "\n",
    "# join the two DF\n",
    "joined = agg_truth.join(agg_pred, 'userID')\n",
    "joined.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "\n",
    "k = 15  # recommend top k from predictions\n",
    "rdds = joined.rdd.map(lambda row: (row[1], row[2][:k]))\n",
    "metrics = RankingMetrics(rdds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38449735449735445"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.meanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20952380952380956"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precisionAt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "??metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

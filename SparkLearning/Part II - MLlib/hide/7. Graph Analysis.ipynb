{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Learning Note - Graph Analysis\n",
    "Jia Geng | gjia0214@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Graph Analysis with Spark\n",
    "\n",
    "Graphs are a natural way of describing relationships and many different problem sets, and Spark provides serveral ways of working in this analytics paradigm. Some business user case include:\n",
    "- detecting credit card fraud\n",
    "- modif finding\n",
    "- determining importance of papers in bibliographic networks\n",
    "- page ranking\n",
    "\n",
    "Spark has a RDD-based library for performning graph processing: `GraphX`. `GraphX` provides some low level interface that was extremely powerful, but wasn't easy to use or optimize. \n",
    "\n",
    "`GraphFrames` extend `GraphX` to provide a DataFrame level API and support for Spark's different language bindings so that users of Python can take advantage of the scalability of the tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6 (default, Jan  8 2020, 19:59:22) \n",
      "[GCC 7.3.0] :: Anaconda, Inc. on linux\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      "Ivy Default Cache set to: /home/jgeng/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jgeng/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/home/jgeng/anaconda3/envs/ml/lib/python3.7/site-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-75448d96-b263-4711-9f19-5d1b1e73d4e8;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.6.0-spark2.3-s_2.11 in spark-packages\n",
      "\tfound com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central\n",
      "\tfound com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.11.0 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.7 in central\n",
      ":: resolution report :: resolve 185ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\tcom.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]\n",
      "\tcom.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]\n",
      "\tgraphframes#graphframes;0.6.0-spark2.3-s_2.11 from spark-packages in [default]\n",
      "\torg.scala-lang#scala-reflect;2.11.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.7 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-75448d96-b263-4711-9f19-5d1b1e73d4e8\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/6ms)\n",
      "20/05/07 15:54:10 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.1.73 instead (on interface enp3s0)\n",
      "20/05/07 15:54:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "20/05/07 15:54:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.5\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.7.6 (default, Jan  8 2020 19:59:22)\n",
      "SparkSession available as 'spark'.\n",
      ">>> "
     ]
    }
   ],
   "source": [
    "!set PYSPARK_DRIVER_PYTHON=jupyter\n",
    "!set PYSPARK_DRIVER_PYTHON_OPTS=notebook\n",
    "!pyspark --packages graphframes:graphframes:0.6.0-spark2.3-s_2.11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Example').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jgeng/anaconda3/envs/ml/bin/jupyter\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/jgeng/anaconda3/envs/ml/lib/python3.7/site-packages/jupyter_core/command.py\", line 247, in main\n",
      "    command = _jupyter_abspath(subcommand)\n",
      "  File \"/home/jgeng/anaconda3/envs/ml/lib/python3.7/site-packages/jupyter_core/command.py\", line 134, in _jupyter_abspath\n",
      "    'Jupyter command `{}` not found.'.format(jupyter_subcommand)\n",
      "Exception: Jupyter command `jupyter-/home/jgeng/anaconda3/envs/ml/bin/find_spark_home.py` not found.\n",
      "/home/jgeng/anaconda3/envs/ml/bin/pyspark: line 24: /bin/load-spark-env.sh: No such file or directory\n",
      "/home/jgeng/anaconda3/envs/ml/bin/pyspark: line 77: /bin/spark-submit: No such file or directory\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_path = '/home/jgeng/Documents/Git/SparkLearning/book_data/bike-data/201508_station_data.csv'\n",
    "trip_path = '/home/jgeng/Documents/Git/SparkLearning/book_data/bike-data/201508_trip_data.csv'\n",
    "stations = spark.read.option('header', True).option('inferSchema', True).csv(station_path)\n",
    "trips = spark.read.option('header', True).option('inferSchema', True).csv(trip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data and nulls\n",
    "\n",
    "stations.show(3)\n",
    "stations.printSchema()\n",
    "stations.cache()\n",
    "print(stations.count())\n",
    "print(stations.na.drop().count())\n",
    "\n",
    "trips.show(3)\n",
    "trips.printSchema()\n",
    "trips.cache()\n",
    "total = trips.count()\n",
    "print(total)\n",
    "print(trips.na.drop().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nulls in trip data\n",
    "# SQL Queries can no recogize the space and special chars such as #\n",
    "# Need to parse these column names\n",
    "trips = spark.read.option('header', True).option('inferSchema', True).csv(trip_path)\n",
    "for col_name in trips.columns:\n",
    "    col_name_formatted =  col_name.replace(' ', '_')\n",
    "    col_name_formatted =  col_name_formatted.replace('#', 'No')\n",
    "    trips = trips.withColumnRenamed(col_name, col_name_formatted)\n",
    "    n = trips.where('{} is null'.format(col_name_formatted)).count()\n",
    "    print('Column {} num of nulls: {}/{}'.format(col_name_formatted, n, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a Graph\n",
    "\n",
    "In spark, to build a graph we need to define the vertices and edges with named columns in DataFrame. For example, to build a directed graph, we need to\n",
    "- specify the vertice column as `id`\n",
    "- specify the edge source and destination as `src` and `dst`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "\n",
    "vertices = spark.createDataFrame([\n",
    "  (\"a\", \"Alice\", 34),\n",
    "  (\"b\", \"Bob\", 36),\n",
    "  (\"c\", \"Charlie\", 30),\n",
    "  (\"d\", \"David\", 29),\n",
    "  (\"e\", \"Esther\", 32),\n",
    "  (\"f\", \"Fanny\", 36),\n",
    "  (\"g\", \"Gabby\", 60)], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "edges = spark.createDataFrame([\n",
    "  (\"a\", \"b\", \"friend\"),\n",
    "  (\"b\", \"c\", \"follow\"),\n",
    "  (\"c\", \"b\", \"follow\"),\n",
    "  (\"f\", \"c\", \"follow\"),\n",
    "  (\"e\", \"f\", \"follow\"),\n",
    "  (\"e\", \"d\", \"friend\"),\n",
    "  (\"d\", \"a\", \"friend\"),\n",
    "  (\"a\", \"e\", \"friend\")\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "\n",
    "g = GraphFrame(vertices, edges)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------+-----------+---------+-------------+------------+\n",
      "|station_id|                  id|      lat|       long|dockcount|     landmark|installation|\n",
      "+----------+--------------------+---------+-----------+---------+-------------+------------+\n",
      "|        46|Washington at Kea...|37.795425|-122.404767|       15|San Francisco|   8/19/2013|\n",
      "+----------+--------------------+---------+-----------+---------+-------------+------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+-------+---------------+--------+\n",
      "|Trip_ID|Duration|     Start_Date|                 src|Start_Terminal|       End_Date|                 dst|End_Terminal|Bike_No|Subscriber_Type|Zip_Code|\n",
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+-------+---------------+--------+\n",
      "| 913460|     765|8/31/2015 23:26|Harry Bridges Pla...|            50|8/31/2015 23:39|San Francisco Cal...|          70|    288|     Subscriber|    2139|\n",
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+-------+---------------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename the vertice columns as id\n",
    "stationVertices = stations.withColumnRenamed('name', 'id').distinct()\n",
    "stationVertices.show(1)\n",
    "\n",
    "# rename columns for the edge as src and dst\n",
    "tripEdges = trips.withColumnRenamed('Start_Station', 'src')\\\n",
    "                        .withColumnRenamed('End_Station', 'dst')\n",
    "tripEdges.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o90.loadClass.\n: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8dda137e38a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pinfo2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GraphFrame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstationGraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstationVertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtripEdges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mstationGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/graphframes/graphframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, v, e)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm_gf_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_java_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm_gf_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/graphframes/graphframe.py\u001b[0m in \u001b[0;36m_java_api\u001b[0;34m(jsc)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_java_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mjavaClassName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"org.graphframes.GraphFramePythonAPI\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetContextClassLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjavaClassName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mnewInstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o90.loadClass.\n: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "from graphframes import GraphFrame\n",
    "\n",
    "??GraphFrame\n",
    "stationGraph = GraphFrame(stationVertices, tripEdges)\n",
    "stationGraph.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
